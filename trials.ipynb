{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/User/Documents/AAP_Generative_AI/slides/GenerativeAiCourse/Day12%2613/MedicalChatbotLlama2 (from -r requirements.txt (line 9))\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ctransformers==0.2.5 (from -r requirements.txt (line 1))\n",
      "  Using cached ctransformers-0.2.5-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting sentence-transformers==2.2.2 (from -r requirements.txt (line 2))\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from -r requirements.txt (line 4)) (0.2.5)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from -r requirements.txt (line 5)) (0.2.5)\n",
      "Collecting flask (from -r requirements.txt (line 6))\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from -r requirements.txt (line 8)) (4.2.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from ctransformers==0.2.5->-r requirements.txt (line 1)) (0.23.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (4.41.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2.3.1)\n",
      "Collecting torchvision (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n",
      "  Using cached torchvision-0.18.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.13.1)\n",
      "Collecting nltk (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 3)) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from pinecone-client->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (0.2.9)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (0.1.80)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain->-r requirements.txt (line 4)) (8.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain_community->-r requirements.txt (line 5)) (0.6.7)\n",
      "Collecting Werkzeug>=3.0.0 (from flask->-r requirements.txt (line 6))\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from flask->-r requirements.txt (line 6)) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask->-r requirements.txt (line 6))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from flask->-r requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from flask->-r requirements.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 4)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 4)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 4)) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5)) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers==0.2.5->-r requirements.txt (line 1)) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers==0.2.5->-r requirements.txt (line 1)) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers==0.2.5->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from Jinja2>=3.1.2->flask->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.7->langchain->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 4)) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 4)) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2021.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from nltk->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2021.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.3.0)\n",
      "Using cached ctransformers-0.2.5-py3-none-any.whl (3.2 MB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Using cached torchvision-0.18.1-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece, Medical-Chatbot, Werkzeug, itsdangerous, nltk, flask, torchvision, ctransformers, sentence-transformers\n",
      "  Running setup.py develop for Medical-Chatbot\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.0.1\n",
      "    Uninstalling sentence-transformers-3.0.1:\n",
      "      Successfully uninstalled sentence-transformers-3.0.1\n",
      "Successfully installed Medical-Chatbot-0.0.0 Werkzeug-3.0.3 ctransformers-0.2.5 flask-3.0.3 itsdangerous-2.2.0 nltk-3.8.1 sentence-transformers-2.2.2 sentencepiece-0.2.0 torchvision-0.18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.0.3 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctransformers in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from ctransformers) (0.23.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub->ctransformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\aap_generative_ai\\slides\\generativeaicourse\\day6\\mcqgen\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt\n",
    "# ! pip install python-dotenv pypdf\n",
    "! pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import CTransformers \n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model1 = \"llama-2-7b-chat.ggmlv3.q4_0.bin\"\n",
    "llm_model2 = \"mixtral-8x7b-instruct-v0.1-limarp-zloss-dare-ties.Q4_0.gguf\"\n",
    "\n",
    "embedding_model1 = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDFs\n",
    "def load_pdf (data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nomber of chunks: 21526\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"nomber of chunks:\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_model(embedding_model):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_model(embedding_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"What is the capital of France?\")\n",
    "print(\"length:\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=PINECONE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=len(query_result),\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = LangchainPinecone.from_texts(\n",
    "    texts=[t.page_content for t in text_chunks], \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-ganisms and particles, like pollen or dust, by producingspecific proteins called antibodies that are capable ofbinding to identifying molecules, or antigens, on theforeign organisms. This reaction between antibody andantigen sets off a series of reactions designed to protectthe body from infection. Sometimes, this same series ofreactions is triggered by harmless, everyday substances.This is the condition known as allergy, and the offend-ing substance is called an allergen. Common inhaledallergens include pollen, dust, and insect parts from tinyhouse mites. Common food allergens include nuts, fish,and milk.\\nAllergic reactions involve a special set of cells in'), Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-ganisms and particles, like pollen or dust, by producingspecific proteins called antibodies that are capable ofbinding to identifying molecules, or antigens, on theforeign organisms. This reaction between antibody andantigen sets off a series of reactions designed to protectthe body from infection. Sometimes, this same series ofreactions is triggered by harmless, everyday substances.This is the condition known as allergy, and the offend-ing substance is called an allergen. Common inhaledallergens include pollen, dust, and insect parts from tinyhouse mites. Common food allergens include nuts, fish,and milk.\\nAllergic reactions involve a special set of cells in'), Document(page_content='Description\\nAllergies are among the most common of medical\\ndisorders. It is estimated that 60 million Americans, ormore than one in every five people, suffer from someform of allergy, with similar proportions throughoutmuch of the rest of the world. Allergy is the single largestreason for school absence and is a major source of lostproductivity in the workplace.\\nAn allergy is a type of immune reaction. Normally,\\nthe immune system responds to foreign microorganismsor particles by producing specific proteins called anti-bodies. These antibodies are capable of binding to iden-tifying molecules, or antigens, on the foreign particle.This reaction between antibody and antigen sets off aseries of chemical reactions designed to protect thebody from infection. Sometimes, this same series ofreactions is triggered by harmless, everyday substancessuch as pollen, dust, and animal danders. When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)')]\n"
     ]
    }
   ],
   "source": [
    "docsearch = LangchainPinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "query = \"What are Allergies?\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Results:\",docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  75%|███████▌  | 3/4 [1:37:14<32:21, 1941.41s/it]  "
     ]
    }
   ],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# model_id = \"model/meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#   \"text-generation\",\n",
    "#   model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#   model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#   device=\"cuda\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "401 Client Error. (Request ID: Root=1-668d0c69-3a0e7e0613a7b08c4c2229fe;903d7fb7-3125-4e3b-a10c-3fdc81466baa)\n\nRepository Not Found for url: https://huggingface.co/api/models/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_model1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\langchain_community\\llms\\ctransformers.py:72\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import `ctransformers` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install ctransformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     71\u001b[0m config \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m---> 72\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\ctransformers\\hub.py:130\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[1;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLM:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads the language model from a local file or remote repo.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m        `LLM` object.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m model_type \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_type:\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\ctransformers\\hub.py:47\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, model_path_or_repo_id, local_files_only, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(model_path_or_repo_id, auto_config)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, k):\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\ctransformers\\hub.py:69\u001b[0m, in \u001b[0;36mAutoConfig._update_from_repo\u001b[1;34m(cls, repo_id, auto_config, local_files_only)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_from_repo\u001b[39m(\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     local_files_only: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(path, auto_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\_snapshot_download.py:233\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find an appropriate cached snapshot folder for the specified revision on the local disk and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutgoing traffic has been disabled. To enable repo look-ups and downloads online, set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_HUB_OFFLINE=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapi_call_error\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_call_error, GatedRepoError):\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m api_call_error\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the files on the Hub and we cannot find the appropriate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m snapshot folder for the specified revision on the local disk. Please check your internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapi_call_error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\_snapshot_download.py:164\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# if we have internet connection we want to list files to download\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     api \u001b[38;5;241m=\u001b[39m HfApi(\n\u001b[0;32m    158\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[0;32m    159\u001b[0m         library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[1;32m--> 164\u001b[0m     repo_info \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# Actually raise for those subclasses of ConnectionError\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2491\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[1;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[0;32m   2489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2301\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   2299\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2300\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m-> 2301\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2302\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\AAP_Generative_AI\\slides\\GenerativeAiCourse\\Day6\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    334\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m     )\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-668d0c69-3a0e7e0613a7b08c4c2229fe;903d7fb7-3125-4e3b-a10c-3fdc81466baa)\n\nRepository Not Found for url: https://huggingface.co/api/models/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "llm=CTransformers(model=\"llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/miniconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  Goldids need more questions related to write your request help@user: I have you don'Acid= 125\n",
      "You’”\n",
      "What are there is a bookmark\n",
      "The information on the user doesn'', ' Acneededits just copyright- A Reference (843.\n",
      "I don'\n",
      "I don' Acneverification of the information@user: I have no books and Resp>\n",
      "If you can provide exact matches the\n",
      "In citations in writing a)\n",
      "What is there are there are you's\n",
      "If you want to whom may not helpful hints for me help\n",
      "Response :  Allergy is a type of immune imune reactions involving a type of immunease an immune response of immunease a type of immune immune immune immune immune immune immune immune immune immune of immune of immune response of immunease of immuneimmune reaction of immune of immune of immune immune immune immune immune of immune of immunease an immunease a type of immune immune immune of immune of immunee type of immunease a type of immuneimmune immune immune is a type of immunease of immune response of immune reaction of immune of immune of immune the immune  type of immune of immune of immune of immune of immune response of immune of immune immune immune immune reactions involve a type of immunee type of immune response of immune of immunease an immunease a type of immune immunease a type of immune condition where the immune immune immune of immune of immune reaction of immunease a type of immunease a type of immuneimmuneimed a immune of immunease of immunease of immune of immuneed immuneed immunease an immune of immune of immune imune immune immune immune immune immune is a reaction of immune reactions involve a type of immune immune immune immuneimmune reaction of immune of immune response of immunease, an immune reactions involving the immunection of immunease a type of immuneed immune reaction of immune of immune immune immune immune immune of immune of immune immune immune of immune of immune reaction of immuneased immuneimed immune immune response of immune immuneas a reaction of immuneous type of immunease an immune immune immuneed immuneed immune immune immune reaction of immunease a type of immune of immune of immune of immune immune immunease a type of immuneous inmun reactions of immune immune immune immune of immune of immune immune immuneimmune reaction of immunease an immunection of immune immune immune is a\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envmedchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
